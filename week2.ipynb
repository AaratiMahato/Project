{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "4.1. Text Processing Setup"
      ],
      "metadata": {
        "id": "mpynCHfOjgyy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAYXeNBnWmPU",
        "outputId": "3647e922-641b-4b7b-9d2d-e9f18d3c404b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "nltk . download ('stopwords')\n",
        "nltk . download ('punkt')\n",
        "nltk . download ('wordnet')\n",
        "import os\n",
        "import string\n",
        "import logging\n",
        "import re\n",
        "from collections import defaultdict , Counter\n",
        "from nltk . corpus import stopwords\n",
        "from nltk . tokenize import word_tokenize\n",
        "from nltk . stem import WordNetLemmatizer\n",
        "\n",
        "STOPWORDS = set( stopwords . words ('english') )\n",
        "LEMMATIZER = WordNetLemmatizer ()\n",
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "    # Lowercasing and tokenizing the document\n",
        "    tokens = re.findall(r'\\w+', text.lower())\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "stop_words = {\"the\", \"is\", \"and\", \"to\", \"in\", \"it\"}  # Example stop words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2. Loading Documents\n"
      ],
      "metadata": {
        "id": "tiJsLwdIjrcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = {\n",
        "    1: \"The first document is about Python programming.\",\n",
        "    2: \"The second document discusses JavaScript and web development.\",\n",
        "    3: \"Python is a popular programming language.\",\n",
        "    # Add more documents...\n",
        "}\n"
      ],
      "metadata": {
        "id": "g1dSvJLxbdVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3. Inverted Index Construction"
      ],
      "metadata": {
        "id": "3bTdg1iAjyKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_inverted_index(documents):\n",
        "    inverted_index = defaultdict(set)\n",
        "    for doc_id, text in documents.items():\n",
        "        tokens = preprocess(text)\n",
        "        for token in tokens:\n",
        "            inverted_index[token].add(doc_id)\n",
        "    return inverted_index\n",
        "\n",
        "inverted_index = build_inverted_index(documents)\n"
      ],
      "metadata": {
        "id": "47kQjYfsbgNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4. Boolean Retrieval"
      ],
      "metadata": {
        "id": "Gqz4UyOOj02A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle Boolean queries (AND, OR, NOT)\n",
        "def boolean_retrieval(query, inverted_index):\n",
        "    query_terms = query.split()\n",
        "    result = set()\n",
        "\n",
        "    if \"AND\" in query_terms:\n",
        "        terms = [term for term in query_terms if term != \"AND\"]\n",
        "        if terms:\n",
        "            result = set.intersection(*[inverted_index[term] for term in terms if term in inverted_index])\n",
        "\n",
        "    elif \"OR\" in query_terms:\n",
        "        terms = [term for term in query_terms if term != \"OR\"]\n",
        "        # Check if there are any terms after filtering out \"OR\"\n",
        "        if terms:\n",
        "            # Create a set from the first term to use as the initial set for union\n",
        "            result = inverted_index[terms[0]]\n",
        "            # Perform union with the rest of the terms\n",
        "            for term in terms[1:]:\n",
        "                if term in inverted_index:\n",
        "                    result = result.union(inverted_index[term])\n",
        "\n",
        "    elif \"NOT\" in query_terms:\n",
        "        not_term = query_terms[1]  # Expecting format like: NOT term\n",
        "        if not_term in inverted_index:\n",
        "            result = set(documents.keys()) - inverted_index[not_term]\n",
        "\n",
        "    else:\n",
        "        result = inverted_index[query] if query in inverted_index else set()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "E9Q1j10PdGPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the inverted index from documents\n",
        "inverted_index = build_inverted_index(documents)"
      ],
      "metadata": {
        "id": "svuOE-T7fYdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.5. Query Processing"
      ],
      "metadata": {
        "id": "h3GXUQqOkL1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example queries\n",
        "queries = [\n",
        "    \"Python AND programming\",\n",
        "    \"JavaScript OR Python\",\n",
        "    \"Python NOT JavaScript\",\n",
        "    \"machine OR learning\",\n",
        "    \"NOT JavaScript\"\n",
        "]\n",
        "\n",
        "# Processing each query and displaying the result\n",
        "for query in queries:\n",
        "    result_docs = boolean_retrieval(query, inverted_index)\n",
        "    print(f\"Query: '{query}' -> Retrieved Documents: {result_docs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzqmyJsbfb9B",
        "outputId": "72ea5850-0635-493c-de7f-baafe90be791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'Python AND programming' -> Retrieved Documents: {1, 3}\n",
            "Query: 'JavaScript OR Python' -> Retrieved Documents: set()\n",
            "Query: 'Python NOT JavaScript' -> Retrieved Documents: set()\n",
            "Query: 'machine OR learning' -> Retrieved Documents: set()\n",
            "Query: 'NOT JavaScript' -> Retrieved Documents: {1, 2, 3}\n"
          ]
        }
      ]
    }
  ]
}